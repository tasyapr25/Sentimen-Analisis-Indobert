# -*- coding: utf-8 -*-
"""1CrawlingData.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14UwhXgXkLmfGXo1ZvZBDIgo-fHKHYPGE
"""

#twitter token

twitter_auth_token = '1f1dc7394044bf669f218e23d0c8cf68ef482163'

!pip install pandas

!sudo apt-get update
!sudo apt-get install -y ca-certificates curl gnupg
!sudo mkdir -p /etc/apt/keyrings
!curl -fsSL https://deb.nodesource.com/gpgkey/nodesource-repo.gpg.key | sudo gpg --dearmor -o /etc/apt/keyrings/nodesource.gpg

!NODE_MAJOR=20 && echo "deb [signed-by=/etc/apt/keyrings/nodesource.gpg] https://deb.nodesource.com/node_$NODE_MAJOR.x nodistro main" | sudo tee /etc/apt/sources.list.d/nodesource.list

!sudo apt-get update
!sudo apt-get install nodejs -y

!node -v

#crawl data

filename = "keluarga_pejabat_10171116.csv"
search_keyword = 'keluarga pejabat since:2024-10-17 until:2024-11-16 lang:id'
limit = 5000

!npx --yes tweet-harvest@2.6.1 -o "{filename}" -s "{search_keyword}" --tab "LATEST" -l {limit} --token {twitter_auth_token}

Aimport pandas as pd

#specify the path to your CSV file
file_path = f"tweets-data/{filename}"

#read the CSV file into a pandas DataFrame
df = pd.read_csv(file_path, delimiter=",")

#display the DataFrame
display(df)