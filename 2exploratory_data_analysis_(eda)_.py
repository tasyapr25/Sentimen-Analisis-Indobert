# -*- coding: utf-8 -*-
"""2Exploratory Data Analysis (EDA) .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zd_5r-L0LIN62R_Sbi1MSg6Nv_D45_o0
"""

# Step 1: Install dan Import Library
!pip install wordcloud
import pandas as pd
import re
import matplotlib.pyplot as plt
from collections import Counter
from wordcloud import WordCloud
import seaborn as sns
import nltk
nltk.download('punkt')
from nltk.tokenize import word_tokenize
import seaborn as sns
import datetime

# Load dataset
df = pd.read_csv('/content/drive/MyDrive/sentimen/dataset/combine.csv', encoding='latin1')
df.head()

# Keyword relevan topik politik dinasti
keywords = ['politik dinasti', 'dinasti', 'nepotisme', 'trah', 'keluarga', 'penguasa', 'jabatan', 'keluarga politik']

# Load data dengan encoding aman
df = pd.read_csv('/content/drive/MyDrive/sentimen/dataset/combine.csv', encoding='ISO-8859-1')

# Pastikan full_text adalah string
df['full_text'] = df['full_text'].astype(str)

# Gabungkan keyword jadi pola pencarian
import re
pattern = '|'.join([re.escape(kw) for kw in keywords])

# Filter hanya tweet yang mengandung salah satu keyword (case-insensitive)
df_relevan = df[df['full_text'].str.contains(pattern, case=False, na=False)].copy()

print(f"Jumlah tweet relevan: {len(df_relevan)} dari total {len(df)} tweet")

"""# Deskripsi Data"""

# Panjang teks
df_relevan['text_length'] = df_relevan['full_text'].apply(len)

print(f"Panjang rata-rata teks: {df_relevan['text_length'].mean():.2f} karakter")
print(f"Jumlah duplikat: {df_relevan.duplicated(subset='full_text').sum()}")

# Pastikan kolom created_at dalam format datetime
df_relevan['created_at'] = pd.to_datetime(df_relevan['created_at'], errors='coerce')

# Distribusi waktu
print("\nDistribusi tweet per hari:")
print(df_relevan['created_at'].dt.date.value_counts().sort_index())

"""# Data Relevan"""

# 1. Load data
df = pd.read_csv('/content/drive/MyDrive/sentimen/dataset/combine.csv', encoding='ISO-8859-1')

# 2. Definisikan keyword politik dinasti
keywords = ['politik dinasti', 'dinasti', 'nepotisme', 'trah', 'keluarga', 'penguasa', 'jabatan', 'keluarga politik']
pattern = '|'.join([re.escape(kw) for kw in keywords])

# 3. Filter data relevan (case-insensitive)
df['full_text'] = df['full_text'].astype(str)
df_relevan = df[df['full_text'].str.contains(pattern, case=False, na=False)].copy()

print(f"Jumlah tweet relevan sebelum hapus duplikat: {len(df_relevan)}")

# 4. Hapus duplikat berdasarkan teks
df_relevan = df_relevan.drop_duplicates(subset='full_text')
print(f"Jumlah tweet relevan setelah hapus duplikat: {len(df_relevan)}")

# 5. Simpan ke Google Drive
output_path = '/content/drive/MyDrive/sentimen/dataset/tweet_relevan_done.csv'
df_relevan.to_csv(output_path, index=False)

# 6. Tampilkan jumlah akhir data
print("\n‚úÖ Ringkasan:")
print(f"- Jumlah total tweet di awal               : {len(df)}")
print(f"- Jumlah tweet yang relevan               : {len(df[df['full_text'].str.contains(pattern, case=False, na=False)])}")
print(f"- Jumlah tweet relevan & tanpa duplikat (final)     : {len(df_relevan)}")
print(f"\nüìÅ File disimpan di: {output_path}")

"""# Visualisasi Data"""

#wordcloud dari tweet yang relevan
all_words = ' '.join(df_relevan['full_text'])
wordcloud = WordCloud(width=900, height=240, background_color='white').generate(all_words)

plt.figure(figsize=(10,5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Wordcloud Tweet Relevan Politik Dinasti')
plt.show()

# Tambahkan kolom panjang teks setelah data final dibersihkan
df_relevan['text_length'] = df_relevan['full_text'].astype(str).apply(len)

# Visualisasi distribusi panjang teks
import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8,5))
sns.histplot(df_relevan['text_length'], bins=30, kde=True)
plt.title('Distribusi Panjang Teks Tweet Relevan')
plt.xlabel('Jumlah Karakter')
plt.ylabel('Frekuensi')
plt.show()

# Lihat contoh tweet dengan panjang 250-280 karakter
df_relevan[df_relevan['text_length'].between(250, 280)][['full_text']].head(10)

# Pastikan kolom waktu dikonversi ke datetime
df_relevan['created_at'] = pd.to_datetime(df_relevan['created_at'], errors='coerce')

# Hitung jumlah tweet relevan per hari
daily_counts = df_relevan['created_at'].dt.date.value_counts().sort_index()

# Visualisasi tren harian
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
daily_counts.plot(kind='line', marker='o')
plt.title("Jumlah Tweet Relevan per Hari")
plt.xlabel("Tanggal")
plt.ylabel("Jumlah Tweet")
plt.grid(True)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

print(df_relevan['created_at'].dtypes)